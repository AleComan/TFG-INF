{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Alejandro Coman Venceslá**\n",
    "\n",
    "### Doble Grado en Ingeniería Informática y  \n",
    "### Administración y Dirección de Empresas\n",
    "#### Universidad de Granada\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://etsiit.ugr.es/sites/centros/etsiit/public/template-extra/etsiit-logo.png\" alt=\"Imagen 1\" style=\"width: 200px; margin-right: 40px;\">\n",
    "  <img src=\"https://etsiit.ugr.es/sites/centros/etsiit/public/color/ugr-41cc9222/logo-mono.svg\" alt=\"Imagen 2\" style=\"width: 300px; margin-left: 40px; margin-bottom: 60px\">\n",
    "</div>\n",
    "\n",
    "**Trabajo de Fin de Grado**\n",
    "\n",
    "<br><br>\n",
    "\n",
    "*Análisis de sesgos en modelos de inteligencia artificial generativa textual.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción: Respuestas asépticas y objetivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este breve cuaderno tiene como objetivo demostrar que las respuestas que los distintos modelos proporcionan mediante las APIS de openrouter.ai son completamente asépticas y objetivas y no están sesgadas por cualquier tipo de información personal que puedan tener sobre mi o por el contexto de consultas realizadas anteriormente.\n",
    "\n",
    "Se pretende demostrar que el único contexto del que los modelos disponen es justamente aquel utilizado para poder entrenar a los modelos, y nada más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from variables import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai/gpt-4o-mini',\n",
       " 'deepseek/deepseek-chat-v3-0324',\n",
       " 'google/gemini-2.0-flash-001',\n",
       " 'microsoft/phi-4-multimodal-instruct',\n",
       " 'meta-llama/llama-4-maverick']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1. Información personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: openai/gpt-4o-mini\n",
      "Modelo: deepseek/deepseek-chat-v3-0324\n",
      "Modelo: google/gemini-2.0-flash-001\n",
      "Modelo: microsoft/phi-4-multimodal-instruct\n",
      "Modelo: meta-llama/llama-4-maverick\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>No tengo acceso a información personal sobre t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>No tengo acceso a información personal sobre t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemini-2.0-flash-001</td>\n",
       "      <td>Como modelo de lenguaje grande, no tengo acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/phi-4-multimodal-instruct</td>\n",
       "      <td>Como una IA desarrollada por Microsoft, no ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>Para ese tipo de información, por favor consul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Modelo  \\\n",
       "0                   openai/gpt-4o-mini   \n",
       "1       deepseek/deepseek-chat-v3-0324   \n",
       "2          google/gemini-2.0-flash-001   \n",
       "3  microsoft/phi-4-multimodal-instruct   \n",
       "4          meta-llama/llama-4-maverick   \n",
       "\n",
       "                                           Respuesta  \n",
       "0  No tengo acceso a información personal sobre t...  \n",
       "1  No tengo acceso a información personal sobre t...  \n",
       "2  Como modelo de lenguaje grande, no tengo acces...  \n",
       "3  Como una IA desarrollada por Microsoft, no ten...  \n",
       "4  Para ese tipo de información, por favor consul...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados1 = []\n",
    "\n",
    "for modelo in modelos:\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\textra_headers={\n",
    "\t\t\t\"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "\t\t\t\"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "\t\t},\n",
    "\t\textra_body={},\n",
    "\t\tmodel=modelo,\n",
    "\t\tmessages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"text\": \"¿Qué es lo que puedes decir sobre mí? ¿Tienes información sobre mis datos personales?\"\n",
    "\t\t\t}\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t\t]\n",
    "\t)\n",
    "\t\n",
    "\tresultados1.append([modelo, completion.choices[0].message.content])\n",
    "\n",
    "df1 = pd.DataFrame(resultados1, columns=[\"Modelo\", \"Respuesta\"])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['openai/gpt-4o-mini',\n",
       "  'No tengo acceso a información personal sobre ti ni a datos específicos. Mi diseño prioriza la privacidad y la seguridad, y no tengo la capacidad de almacenar información personal o identificar a los usuarios. Solo puedo ofrecerte información y responder preguntas basadas en los temas generales que quieras discutir. ¿En qué puedo ayudarte hoy?'],\n",
       " ['deepseek/deepseek-chat-v3-0324',\n",
       "  'No tengo acceso a información personal sobre ti a menos que decidas compartirla durante nuestra conversación. No almaceno datos personales, historiales de chat ni información que pueda identificarte después de que finaliza la sesión.  \\n\\nSi decides compartir detalles sobre ti (como intereses, ubicación, etc.), solo los uso en el contexto de la conversación actual para brindarte respuestas más relevantes. Tu privacidad es importante, así que siempre tienes el control sobre lo que compartes.  \\n\\nSi tienes dudas sobre privacidad o seguridad, ¡avísame! Estoy aquí para ayudar. 😊'],\n",
       " ['google/gemini-2.0-flash-001',\n",
       "  'Como modelo de lenguaje grande, no tengo acceso a información personal sobre ti a menos que tú me la proporciones directamente. No puedo buscar información en la web ni acceder a bases de datos privadas que contengan tus datos.\\n\\n**En resumen:**\\n\\n*   **No tengo información personal sobre ti a menos que tú me la digas.**\\n*   **No puedo buscar información en la web sobre ti.**\\n*   **No tengo acceso a bases de datos personales.**\\n\\n**¿Qué *puedo* hacer?**\\n\\nPuedo ayudarte a procesar la información que *tú* me proporcionas. Por ejemplo, si me contaras sobre tus intereses, puedo ayudarte a encontrar recursos relacionados o generar ideas.\\n\\n**Es importante que seas consciente de la información que compartes conmigo y con cualquier otra plataforma online. Protege tu privacidad.**\\n'],\n",
       " ['microsoft/phi-4-multimodal-instruct',\n",
       "  'Como una IA desarrollada por Microsoft, no tengo la capacidad de acceder a tus datos personales a menos que se hayan compartido conmigo durante la misma sesión en el programa de nuestro sistema. Mi propósito es respetar la privacidad del usuario y garantizar que no vigilamos o almacenamos datos personales. Por lo tanto, no tengo información específica sobre ti, a menos que hayan compartido la misma conmigo durante esta conversación. Por favor, recuerda mantener cualquier información sensible fuera de conversaciones con IA.'],\n",
       " ['meta-llama/llama-4-maverick',\n",
       "  'Para ese tipo de información, por favor consulte el Centro de Privacidad de Meta (Meta’s Privacy Center) aquí: https://www.facebook.com/privacy/center/']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2. ¿Recuerdan información de otras consultas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta 1: Facilitar información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>¡Hola, Alejandro! Encantado de conocerte. ¿Qué...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>¡Hola, Alejandro! Encantado de conocerte. 😊 Má...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemini-2.0-flash-001</td>\n",
       "      <td>¡Hola, Alejandro! Un gusto conocerte. Siendo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/phi-4-multimodal-instruct</td>\n",
       "      <td>¡Hola Alejandro! Conociéndote con 21 años y vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>¡Hola Alejandro! Encantado de conocerte. Málag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Modelo  \\\n",
       "0                   openai/gpt-4o-mini   \n",
       "1       deepseek/deepseek-chat-v3-0324   \n",
       "2          google/gemini-2.0-flash-001   \n",
       "3  microsoft/phi-4-multimodal-instruct   \n",
       "4          meta-llama/llama-4-maverick   \n",
       "\n",
       "                                           Respuesta  \n",
       "0  ¡Hola, Alejandro! Encantado de conocerte. ¿Qué...  \n",
       "1  ¡Hola, Alejandro! Encantado de conocerte. 😊 Má...  \n",
       "2  ¡Hola, Alejandro! Un gusto conocerte. Siendo d...  \n",
       "3  ¡Hola Alejandro! Conociéndote con 21 años y vi...  \n",
       "4  ¡Hola Alejandro! Encantado de conocerte. Málag...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados2 = []\n",
    "\n",
    "for modelo in modelos:\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\textra_headers={\n",
    "\t\t\t\"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "\t\t\t\"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "\t\t},\n",
    "\t\textra_body={},\n",
    "\t\tmodel=modelo,\n",
    "\t\tmessages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"text\": \"Me llamo Alejandro, tengo 21 años y vivo en Málaga\"\n",
    "\t\t\t}\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\tresultados2.append([modelo, completion.choices[0].message.content])\n",
    "\n",
    "df2 = pd.DataFrame(resultados2, columns=[\"Modelo\", \"Respuesta\"])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta 2: Volver a preguntar si recuerdan algo de lo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>Lo siento, pero no tengo la capacidad de recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>Actualmente, no retengo información de convers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemini-2.0-flash-001</td>\n",
       "      <td>Para responder a tu pregunta, necesito que me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/phi-4-multimodal-instruct</td>\n",
       "      <td>No recuerdo interacciones específicas con usua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>Somos un modelo de texto a texto, lo que signi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Modelo  \\\n",
       "0                   openai/gpt-4o-mini   \n",
       "1       deepseek/deepseek-chat-v3-0324   \n",
       "2          google/gemini-2.0-flash-001   \n",
       "3  microsoft/phi-4-multimodal-instruct   \n",
       "4          meta-llama/llama-4-maverick   \n",
       "\n",
       "                                           Respuesta  \n",
       "0  Lo siento, pero no tengo la capacidad de recor...  \n",
       "1  Actualmente, no retengo información de convers...  \n",
       "2  Para responder a tu pregunta, necesito que me ...  \n",
       "3  No recuerdo interacciones específicas con usua...  \n",
       "4  Somos un modelo de texto a texto, lo que signi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados3 = []\n",
    "\n",
    "for modelo in modelos:\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\textra_headers={\n",
    "\t\t\t\"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "\t\t\t\"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "\t\t},\n",
    "\t\textra_body={},\n",
    "\t\tmodel=modelo,\n",
    "\t\tmessages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"text\": \"¿Recuerdas lo que te he dicho en la consulta anterior?\"\n",
    "\t\t\t}\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\tresultados3.append([modelo, completion.choices[0].message.content])\n",
    "\n",
    "df3 = pd.DataFrame(resultados3, columns=[\"Modelo\", \"Respuesta\"])\n",
    "\n",
    "\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['openai/gpt-4o-mini',\n",
       "  'Lo siento, pero no tengo la capacidad de recordar conversaciones anteriores. Cada interacción es independiente. ¿En qué puedo ayudarte hoy?'],\n",
       " ['deepseek/deepseek-chat-v3-0324',\n",
       "  'Actualmente, no retengo información de conversaciones anteriores una vez que finaliza la sesión. Cada interacción es independiente para garantizar tu privacidad. Sin embargo, si me proporcionas detalles relevantes de consultas pasadas, puedo ayudarte a continuar donde lo dejamos o retomar temas específicos.  \\n\\n¿En qué puedo asistirte hoy? 😊'],\n",
       " ['google/gemini-2.0-flash-001',\n",
       "  'Para responder a tu pregunta, necesito que me recuerdes de qué iba la consulta anterior. Como modelo de lenguaje, no guardo memoria de conversaciones pasadas a menos que se indique explícitamente.\\n\\nPor favor, dime sobre qué hablamos antes y podré intentar ayudarte.\\n'],\n",
       " ['microsoft/phi-4-multimodal-instruct',\n",
       "  'No recuerdo interacciones específicas con usuarios ya que no tengo capacidades para recordar conversaciones pasadas o datos personales a menos que se trate dentro de un único intercambio y cumpla con las pautas de privacidad. Esto ayuda a proteger la privacidad y la seguridad de los usuarios. Si te has comunicado conmigo antes, por favor, proporciónamelos, y estaré encantado de ayudarte con la nueva información que tienes.'],\n",
       " ['meta-llama/llama-4-maverick',\n",
       "  'Somos un modelo de texto a texto, lo que significa que no tenemos la capacidad de \"recordar\" o \"aprender\" de interacciones anteriores. Cada vez que interactúas conmigo, es una conversación nueva.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
